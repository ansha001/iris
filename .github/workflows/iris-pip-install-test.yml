name: Iris Pip Install Test

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}
  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}

jobs:
  build-container-image:
    runs-on: [self-hosted, mi3008x]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Apptainer (if not available)
        run: |
          if ! command -v apptainer &> /dev/null && ! command -v docker &> /dev/null; then
            echo "Neither Apptainer nor Docker found, installing Apptainer..."
            apt-get update && apt-get install -y software-properties-common
            add-apt-repository -y ppa:apptainer/ppa
            apt-get update && apt-get install -y apptainer
          else
            echo "Container runtime already available"
          fi

      - name: Build Iris container
        run: |
          # Use the universal container build script
          bash .github/scripts/container_build.sh

  test-1-2-4-ranks:
    name: Pip Install Test 1/2/4 Ranks (Parallel)
    needs: build-container-image
    runs-on: [self-hosted, mi3008x]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Cleanup lingering ports before tests
        run: |
          bash .github/scripts/cleanup_ports.sh

      - name: Run pip install tests for 1, 2, 4 ranks in parallel
        run: |
          # Don't use set -e here - we want to handle errors manually for parallel processes
          # Run tests in parallel with different GPU assignments
          # Note: Each test gets 2+ GPUs even if it only uses some of them.
          # This allows tests like test_empty_device_handling to verify that
          # allocating on a different device correctly raises an error.

          echo "::group::Starting parallel tests"
          echo "Starting 1-rank test on GPUs 0,1..."
          bash .github/scripts/container_exec.sh --gpus "0,1" "
            set -e
            pip install git+https://github.com/${{ github.repository }}.git@${{ github.sha }}
            pip install -e .
            for test_file in tests/examples/test_*.py; do
              echo \"Testing: \$test_file with 1 ranks\"
              python tests/run_tests_distributed.py --num_ranks 1 \"\$test_file\" -v --tb=short --durations=10
            done
            for test_file in tests/unittests/test_*.py; do
              echo \"Testing: \$test_file with 1 ranks\"
              python tests/run_tests_distributed.py --num_ranks 1 \"\$test_file\" -v --tb=short --durations=10
            done
          " > /tmp/test_1rank.log 2>&1 &
          PID1=$!

          echo "Starting 2-rank test on GPUs 2,3..."
          bash .github/scripts/container_exec.sh --gpus "2,3" "
            set -e
            pip install git+https://github.com/${{ github.repository }}.git@${{ github.sha }}
            pip install -e .
            for test_file in tests/examples/test_*.py; do
              echo \"Testing: \$test_file with 2 ranks\"
              python tests/run_tests_distributed.py --num_ranks 2 \"\$test_file\" -v --tb=short --durations=10
            done
            for test_file in tests/unittests/test_*.py; do
              echo \"Testing: \$test_file with 2 ranks\"
              python tests/run_tests_distributed.py --num_ranks 2 \"\$test_file\" -v --tb=short --durations=10
            done
          " > /tmp/test_2rank.log 2>&1 &
          PID2=$!

          echo "Starting 4-rank test on GPUs 4,5,6,7..."
          bash .github/scripts/container_exec.sh --gpus "4,5,6,7" "
            set -e
            pip install git+https://github.com/${{ github.repository }}.git@${{ github.sha }}
            pip install -e .
            for test_file in tests/examples/test_*.py; do
              echo \"Testing: \$test_file with 4 ranks\"
              python tests/run_tests_distributed.py --num_ranks 4 \"\$test_file\" -v --tb=short --durations=10
            done
            for test_file in tests/unittests/test_*.py; do
              echo \"Testing: \$test_file with 4 ranks\"
              python tests/run_tests_distributed.py --num_ranks 4 \"\$test_file\" -v --tb=short --durations=10
            done
          " > /tmp/test_4rank.log 2>&1 &
          PID4=$!
          echo "::endgroup::"

          # Wait for all parallel tests and track failures
          echo "::group::Waiting for parallel tests to complete"
          FAIL=0
          FAILED_TESTS=""

          # Wait for each process and capture exit status
          if ! wait $PID1; then
            echo "::error::1-rank test FAILED"
            echo "::group::1-rank test logs"
            cat /tmp/test_1rank.log || true
            echo "::endgroup::"
            FAILED_TESTS="$FAILED_TESTS 1-rank"
            FAIL=1
          else
            echo "✅ 1-rank test passed"
          fi

          if ! wait $PID2; then
            echo "::error::2-rank test FAILED"
            echo "::group::2-rank test logs"
            cat /tmp/test_2rank.log || true
            echo "::endgroup::"
            FAILED_TESTS="$FAILED_TESTS 2-rank"
            FAIL=1
          else
            echo "✅ 2-rank test passed"
          fi

          if ! wait $PID4; then
            echo "::error::4-rank test FAILED"
            echo "::group::4-rank test logs"
            cat /tmp/test_4rank.log || true
            echo "::endgroup::"
            FAILED_TESTS="$FAILED_TESTS 4-rank"
            FAIL=1
          else
            echo "✅ 4-rank test passed"
          fi
          echo "::endgroup::"

          # Clean up log files
          rm -f /tmp/test_1rank.log /tmp/test_2rank.log /tmp/test_4rank.log

          if [ $FAIL -eq 1 ]; then
            echo "::error::Parallel tests failed:$FAILED_TESTS"
            exit 1
          fi

          echo "✅ All parallel tests (1, 2, 4 ranks) passed!"

  test-8-ranks:
    name: Pip Install Test 8 Ranks
    needs: build-container-image
    runs-on: [self-hosted, mi3008x]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Cleanup lingering ports before tests
        run: |
          bash .github/scripts/cleanup_ports.sh

      - name: Run 8-rank pip install test
        run: |
          echo "::group::Running 8-rank test on all GPUs"
          if bash .github/scripts/container_exec.sh --gpus "0,1,2,3,4,5,6,7" "
            set -e
            pip install git+https://github.com/${{ github.repository }}.git@${{ github.sha }}
            pip install -e .
            for test_file in tests/examples/test_*.py; do
              echo \"Testing: \$test_file with 8 ranks\"
              python tests/run_tests_distributed.py --num_ranks 8 \"\$test_file\" -v --tb=short --durations=10
            done
            for test_file in tests/unittests/test_*.py; do
              echo \"Testing: \$test_file with 8 ranks\"
              python tests/run_tests_distributed.py --num_ranks 8 \"\$test_file\" -v --tb=short --durations=10
            done
          "; then
            echo "::endgroup::"
            echo "✅ 8-rank test passed!"
          else
            echo "::endgroup::"
            echo "::error::8-rank test FAILED"
            exit 1
          fi
